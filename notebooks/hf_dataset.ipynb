{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.2 MB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.21.2\n",
      "  Using cached huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.0 MB 102.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Collecting pyarrow-hotfix\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting requests>=2.19.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 5.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.62.1\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "\u001b[K     |████████████████████████████████| 705 kB 96.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 100.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=12.0.0\n",
      "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 40.8 MB 93.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]<=2024.3.1,>=2023.1.0\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 97.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 100.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/dereje_senbatu/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 105.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 69.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 97.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dereje_senbatu/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.0)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 102.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/dereje_senbatu/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/dereje_senbatu/.pyenv/versions/3.10.2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: multidict, idna, frozenlist, yarl, urllib3, charset-normalizer, certifi, attrs, async-timeout, aiosignal, tzdata, tqdm, requests, pyyaml, pytz, numpy, fsspec, filelock, dill, aiohttp, xxhash, pyarrow-hotfix, pyarrow, pandas, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 datasets-2.19.1 dill-0.3.8 filelock-3.14.0 frozenlist-1.4.1 fsspec-2024.3.1 huggingface-hub-0.23.2 idna-3.7 multidict-6.0.5 multiprocess-0.70.16 numpy-1.26.4 pandas-2.2.2 pyarrow-16.1.0 pyarrow-hotfix-0.6 pytz-2024.1 pyyaml-6.0.1 requests-2.32.3 tqdm-4.66.4 tzdata-2024.1 urllib3-2.2.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/dereje_senbatu/.pyenv/versions/3.10.2/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dereje_senbatu/.pyenv/versions/3.10.2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|██████████| 28.7M/28.7M [00:00<00:00, 152MB/s] \n",
      "Downloading data: 100%|██████████| 9.36M/9.36M [00:00<00:00, 88.3MB/s]\n",
      "Generating train split: 100%|██████████| 22207/22207 [00:00<00:00, 113648.51 examples/s]\n",
      "Generating test split: 100%|██████████| 7338/7338 [00:00<00:00, 124040.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 22207\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7338\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Swahili News dataset\n",
    "dataset = load_dataset(\"swahili_news\")\n",
    "\n",
    "# Display information about the dataset\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [' Bodi ya Utalii Tanzania (TTB) imesema, itafanya misafara ya kutangaza utalii kwenye miji minne nchini China kati ya Juni 19 hadi Juni 26 mwaka huu.Misafara hiyo itatembelea miji ya Beijing Juni 19, Shanghai Juni 21, Nanjig Juni 24 na Changsha Juni 26.Mwenyekiti wa bodi TTB, Jaji Mstaafu Thomas Mihayo ameyasema hayo kwenye mkutano na waandishi wa habari jijini Dar es Salaam.“Tunafanya jitihada kuhakikisha tunavuna watalii wengi zaidi kutoka China hasa tukizingatia umuhimu wa soko la sekta ya utalii nchini,” amesema Jaji Mihayo.Novemba 2018 TTB ilifanya ziara kwenye miji ya Beijing, Shanghai, Chengdu, Guangzhou na Hong Kong kutangaza vivutio vya utalii sanjari kuzitangaza safari za ndege za Air Tanzania.Ziara hiyo inaelezwa kuzaa matunda ikiwa ni pamoja na watalii zaidi ya 300 kuja nchini Mei mwaka huu kutembelea vivutio vya utalii.', ' PENDO FUNDISHA-MBEYA RAIS Dk. John Magufuri, ametangaza kuwafukuza\\nkazi wakurugenzi wote wa halmashauri ambao watabainika kukiuka sheria ya\\nufutaji wa tozo za ushuru wa mazao. Alisema baada ya kuingia madarakani, Serikali\\niliondoa tozo 80, miongoni mwa hizo tozo ushuru wakulima ambao walikuwa\\nwakilipa mazao kutoka halmashauri moja kwenda nyingine. Rais Dk. Magufuli, aliyasema hayo juzi alipokuwa\\nakiwahutubia wakazi wa Wilaya ya Kyela katika ziara ya kikazi ya siku 10 mkoani\\nMbeya. Alisema, sheria ya ufutaji wa tozo hizo\\nzilipitishwa na Bunge hivyo hakuna mtu yoyote wa kuitengua na kwamba Mkurugenzi\\natakaye itengua atakuwa umevunja sheria na anawajibu wa kufukuzwa kazi. Alisema licha ya kupitishwa kwa sheria hiyo wapo\\nbaadhi ya watendaji wameendelea kuwatoza ushuru wananchi kwa kisingizio cha\\nkupandisha ukusanyaji wa mapato hilo jambo sitaki kulisikia. “Wapo watendaji\\nwanasema kufutwa kwa ushuru kunapunguza mapato, narudia kwa viongozi wote, wakurugenzi,\\nwatendaji wote wa halmashauri msiwatoze wananchi ushuru wa mzigo wowote usio\\nzidi tani moja,”alisema. Hata hivyo, alitoa wito kwa watendaji kuzingatia\\nsheria ya kuwalinda wakulima na ndio maana serikali iliziondoa tozo 80.', 'Mwandishi Wetu -Singida BENKI ya NMB imetoa msaada wa vifaa mbalimbali vyenye thamani ya zaidi ya Sh milioni 200 katika wilaya kadhaa nchini. Misaada iliyotolewa na benki hiyo inayoongoza kwa kutengeneza faida kati ya benki zote zinazofanya biashara humu nchini ndani ya miezi mitano mwaka huu, inahusisha vifaa vya ujenzi, madawati na vifaa vingine vinavyowezesha ukamilishaji wa miradi ya afya,elimu na usalama wa raia. Benki\\xa0 ya NMB imeshatoa\\xa0 msaada wa\\xa0 vifaa vyenye thamani ya zaidi ya Sh milioni 200 kwa mikoa ya Kanda ya Kati. Akifafanua kuhusu misaada hiyo wakati akikabidhi msaada wa madawati na vitanda kwa baadhi ya shule katika Halmashauri ya Wilaya ya Iramba mkoani ingida, Meneja wa Kanda ya Kati wa NMB, Nsolo Mlozi, alibainisha kuwa misaada hiyo ya zaidi ya Sh milioni 200 iliyotolewa imelenga sekta ya elimu, afya\\xa0 na majanga kwa mikoa mitatu ya\\xa0 Kanda ya kati. Akikabidhi msaada wa madawati na vitanda kwa baadhi ya shule za Halmashauri ya Wilaya ya Iramba, MkoaniSingida, katika shule ya Sekondari ya New Kiomboi, Mlozi alisema fedha hizo zilizotolewa na NMB zimetumika kununua madawati, viti vya shule za sekondari,vitanda na vifaa tiba kwenye sekta ya afya. Aidha, alisema lengo la misaada hiyo ni kuunga mkono juhudi za serikali kuwahudumia wananchi kwenye sekta mbalimbali. Pia alisema misaada hiyo imekabidhiwa kwa baadhi ya shule, zahanati, hospitali katika mikoa ya Singida, Dodoma na Manyara. Pia NMB walikabidhi madawati 250 na vitanda 80 vyenye thamani ya zaidi ya Sh milioni 29.5 kwa baadhi ya shule za Wilaya ya Iramba mkoani humo. Katika hatua nyingine, Benki hiyo imevipatia kituo cha Polisi Wilaya ya Kilosa mkoani Morogoro pamoja na shule ya msingi Msowelo mabati 160 yenye thamani ya Sh5 milioni kwa ajili ya kuezekea maboma. NMB iliamua kutoa msaada huo ikiwa ni mpango wa kuzipunguza baadhi ya changamoto kwa taasisi za serikali hapa nchini, Meneja wa NMB kanda ya mashariki, Baraka Ladislaus, alisema na kubainisha kuwa msaada huo ni sehemu ya mikakati ya benki hiyo kurudisha sehemu ya faida kwa jamii ili kusaidia kuinua miradi ya maendeleo. Baraka alisema kuwa kati ya mabati hayo, kituo cha polisi wilaya kimepa tamabati 80 huku shule ya msingi Msowelo nayo ikipata mabati 80.', ' TIMU ya taifa ya Tanzania, Serengeti Boys jana ilijiweka katika nafasi fi nyu katika mashindano ya Mataifa ya Afrika kwa wachezaji wenye umri chini ya miaka 17 baada ya kuchapwa mabao 3-0 na Uganda kwenye Uwanja wa Taifa, Dar es Salaam.Uganda waliandika bao lao la kwanza katika dakika ya 15 lililofungwa na Kawooya Andrew akiunganisha wavuni krosi ya Najibu Viga huku lile la pili likifungwa na Asaba Ivan katika dakika ya 27 Najib Yiga.Serengeti Boys iliendelea kulala, Yiga aliifungia Uganda bao la tatu na la ushindi na kuifanya Serengeti kushika mkia katika Kundi A na kuacha simanzi kwa wapenzi wa soka nchini. Serengeti Boys inasubiri mchezo wa mwisho dhidi ya Senegal huku Nigeria ikisonga mbele baada ya kushinda mchezo wake wa awali kwenye uwanja huo na kufikisha pointi sita baada ya kushinda ule wa ufunguzi dhidi ya Tanzania.', ' Na AGATHA CHARLES –\\xa0DAR ES SALAAM ALIYEKUWA Katibu wa Bunge na Serikali za Mitaa katika Sekretarieti ya Chama cha ACT-Wazalendo, Habibu Mchange, amejiondoa uanachama wa chama hicho na kujiweka kando na siasa. Taarifa ya uamuzi huo wa Mchange ilisambazwa jana katika mitandao ya kijamii, ikionyesha kuandikwa naye huku ikiambatanishwa na namba yake ya simu. Katika andiko hilo, Mchange aliyewahi kuwa mwanachama wa Chadema kabla hajahamia ACT Wazalendo, alisema aliamua kujitoa rasmi katika ushiriki wa aina yoyote ya siasa ili apate muda zaidi wa kusimamia shughuli zake za kijasiriamali. Mchange alisema ameamua kujiengua na siasa ili kutoa fursa na huduma sawa kwa viongozi na wanachama wa vyama vyote vya siasa. “Kwa moyo mkunjufu kabisa na kwa mapenzi mema na taifa langu, ninathibitisha kwamba nimejitoa rasmi katika ushiriki wa aina yote ya siasa ili nipate muda mwingi zaidi kufanya na kusimamia shughuli zangu za kijasiriamali zinazonitaka nitoe fursa na huduma sawa kwa viongozi na wanachama wa vyama vyote vya siasa,” alisema Mchange. Alisema kutokana na uamuzi huo ambao aliomba uheshimiwe, lolote atakalolifanya lisihusishwe na chama bali iwe ni msimamo wake mwenyewe kama mtu huru asiye na chama. “Ninafahamu kuwa mwanachama wa chama cha siasa ni haki yangu ya kikatiba, lakini nimeamua kuihifadhi kwa sasa mpaka hapo nitakapoona inafaa kufanya vinginevyo. Ninawatakia kila la heri waliokuwa wanachama wenzangu wa ACT Wazalendo katika kuyafikia malengo ya msingi ya uanzishwaji wa chama hicho,” alisema Mchange. Mchange alisema kujiondoa kwake kusihesabiwe kama sehemu ya kukwamisha au kurudisha nyuma matarajio na au malengo ya chama hicho bali ichukuliwe kama chachu ya kufika mbali. “Msivunjike moyo, msirumbane, pendaneni, heshimianeni na shikamaneni ili mfikie lengo. Nitabaki na kuendelea kuwa ndugu yenu, rafiki na swahiba. Zaidi Mtanzania mwenzenu. Tutaendelea kushirikiana katika mambo yote ya kijamii na kimaisha yasiyohusiana na mlengo wa kiitikadi wa kisiasa,” alisema Mchange. Mchange alishika nafasi mbalimbali katika chama hicho ikiwamo Katibu wa Mipango na Mikakati, Mjumbe wa Kamati Kuu, Mjumbe wa Halmashauri Kuu na Mjumbe wa Mkutano Mkuu. MTANZANIA Jumapili lilimtafuta Mchange kwa simu kuthibitisha andiko hilo, lakini hakuweza kupatikana. Alipotafutwa Ofisa Habari wa ACT-Wazalendo, Abdallah Khamis, alikiri andiko hilo kuwa ni la Mchange. Mchange anakuwa mwanasiasa wa tatu kuondoka ACT-Wazalendo mwaka huu baada ya aliyekuwa Katibu Mkuu wa chama hicho, Samson Mwigamba kuachia nafasi yake na kwenda masomoni nchini Kenya, Aprili mwaka huu. Miezi michache baadaye, Novemba mwaka huu mwanasiasa Moses Machali naye alitangaza kujiondoa rasmi chama hicho na kuunga mkono jitihada zinazofanywa na Rais Dk. John Magufuli. Machali aliwahi kuwa Mbunge wa Kasulu Mjini kupitia Chama cha NCCR-Mageuzi kabla ya mwaka jana kushindwa kutetea jimbo lake kupitia ACT-Wazalendo.'], 'label': [0, 1, 0, 2, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few rows of the dataset\n",
    "print(dataset['train'][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Convert the dataset to a Pandas DataFrame\n",
    "df_train = pd.DataFrame(dataset['train'])\n",
    "df_test = pd.DataFrame(dataset['test'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_train.to_csv('../data/hf_dataset/swahili_news_train.csv', index=False)\n",
    "df_test.to_csv('../data/hf_dataset/swahili_news_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0   BUNGE limehakikishiwa kuwa hakuna changamoto ...      1\n",
      "1   Twiga ilicheza mechi ya kirafiki na Kenya kwe...      2\n",
      "2  ['Miaka mitano iliyopita Harry Maguire alikuwa...      2\n",
      "3  Bethsheba Wambura, Dar es Salaam Msanii wa Bon...      4\n",
      "4  \\nMwekezaji wa Klabu ya Simba, Mohammed Dewji ...      2\n"
     ]
    }
   ],
   "source": [
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format our dataset with hf dataset\n",
    "df_burudani = pd.read_csv('../data/bbc/burudani/burudani.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column called 'label\n",
    "df_burudani['label'] = 'burudani'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  Orodha kamili ya washindi na walioteuliwa kwen...   \n",
      "1  Oscars academy awards: mambo 11 unayohitaji ku...   \n",
      "2  Ma-dj wa kike wa iran wanaotumbuiza na kuvunja...   \n",
      "3  Nguvu ya familia ilivyompa  nguvu mr. blue kur...   \n",
      "4  Bob marley: mambo manne ambayo hukuyajua kumhu...   \n",
      "\n",
      "                                             Content     label  \n",
      "0  Chanzo cha picha, Getty Images\\nWasanii bora w...  burudani  \n",
      "1  Chanzo cha picha, Getty Images\\nKumekuwa na ha...  burudani  \n",
      "2  Ngoma za watu wa jinsia tofauti ni kinyume cha...  burudani  \n",
      "3  Mwanamuziki wa kizazi kipya ‘Bongo flava’ Herr...  burudani  \n",
      "4  Chanzo cha picha, Getty Images\\nFilamu mpya, O...  burudani  \n"
     ]
    }
   ],
   "source": [
    "print(df_burudani.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop unnecessary column\n",
    "df_burudani.drop(columns=['Title'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  Chanzo cha picha, Getty Images\\nWasanii bora w...  burudani\n",
      "1  Chanzo cha picha, Getty Images\\nKumekuwa na ha...  burudani\n",
      "2  Ngoma za watu wa jinsia tofauti ni kinyume cha...  burudani\n",
      "3  Mwanamuziki wa kizazi kipya ‘Bongo flava’ Herr...  burudani\n",
      "4  Chanzo cha picha, Getty Images\\nFilamu mpya, O...  burudani\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#rename column\n",
    "df_burudani.rename(columns={'Content': 'text'}, inplace=True)\n",
    "print(df_burudani.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = ['uchumi', 'kitaifa', 'michezo', 'kimataifa', 'burudani', 'afya']\n",
    "label_to_id = {label: idx for idx, label in enumerate(label_mapping)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Chanzo cha picha, Getty Images\\nWasanii bora w...      4\n",
      "1  Chanzo cha picha, Getty Images\\nKumekuwa na ha...      4\n",
      "2  Ngoma za watu wa jinsia tofauti ni kinyume cha...      4\n",
      "3  Mwanamuziki wa kizazi kipya ‘Bongo flava’ Herr...      4\n",
      "4  Chanzo cha picha, Getty Images\\nFilamu mpya, O...      4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the label mapping\n",
    "label_mapping = ['uchumi', 'kitaifa', 'michezo', 'kimataifa', 'burudani', 'afya']\n",
    "label_to_id = {label: idx for idx, label in enumerate(label_mapping)}\n",
    "\n",
    "# Load your new dataset\n",
    "# new_df = pd.read_csv('new_swahili_news.csv')\n",
    "\n",
    "# Map text labels to numerical labels in the new dataset\n",
    "df_burudani['label'] = df_burudani['label'].map(label_to_id)\n",
    "\n",
    "# Display the new DataFrame to ensure labels are mapped correctly\n",
    "print(df_burudani.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "df_burudani.to_csv('../data/hf_dataset/df_burudani_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our CSV files into DataFrames\n",
    "df_michezo = pd.read_csv('../data/bbc/michezo/michezo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text    label\n",
      "0  Chanzo cha picha, Getty Images\\nPazia limeshus...  michezo\n",
      "1  Chanzo cha picha, Getty Images\\nManchester Uni...  michezo\n",
      "2  Chanzo cha picha, Getty Images\\nMeneja wa Burn...  michezo\n",
      "3  Chanzo cha picha, Getty Images\\nManchester Uni...  michezo\n",
      "4  Chanzo cha picha, Getty Images\\nAston Villa wa...  michezo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#add new column called 'label\n",
    "df_michezo['label'] = 'michezo'\n",
    "\n",
    "#drop unnecessary column\n",
    "df_michezo.drop(columns=['Title'], inplace=True)\n",
    "\n",
    "#rename column\n",
    "df_michezo.rename(columns={'Content': 'text'}, inplace=True)\n",
    "print(df_michezo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Chanzo cha picha, Getty Images\\nPazia limeshus...      2\n",
      "1  Chanzo cha picha, Getty Images\\nManchester Uni...      2\n",
      "2  Chanzo cha picha, Getty Images\\nMeneja wa Burn...      2\n",
      "3  Chanzo cha picha, Getty Images\\nManchester Uni...      2\n",
      "4  Chanzo cha picha, Getty Images\\nAston Villa wa...      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the label mapping\n",
    "label_mapping = ['uchumi', 'kitaifa', 'michezo', 'kimataifa', 'burudani', 'afya']\n",
    "label_to_id = {label: idx for idx, label in enumerate(label_mapping)}\n",
    "\n",
    "# Load your new dataset\n",
    "# new_df = pd.read_csv('new_swahili_news.csv')\n",
    "\n",
    "# Map text labels to numerical labels in the new dataset\n",
    "df_michezo['label'] = df_michezo['label'].map(label_to_id)\n",
    "\n",
    "# Display the new DataFrame to ensure labels are mapped correctly\n",
    "print(df_michezo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "df_michezo.to_csv('../data/hf_dataset/df_michezo-new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0  Chanzo cha picha, Getty Images\\nHabari za hivi...  afya\n",
      "1  Chanzo cha picha, Getty Images\\nKiungulia amba...  afya\n",
      "2  Kat Watkins, mwanamke anayetumia kiti cha magu...  afya\n",
      "3  Chanzo cha picha, GETTTY IMAGES\\nMaumivu ya mo...  afya\n",
      "4  Chanzo cha picha, Getty Images\\nOnur Erim\\nBBC...  afya\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load our CSV files into DataFrames\n",
    "df_afla = pd.read_csv('../data/bbc/afla/afla.csv')\n",
    "#add new column called 'label\n",
    "df_afla['label'] = 'afya'\n",
    "\n",
    "#drop unnecessary column\n",
    "df_afla.drop(columns=['Title'], inplace=True)\n",
    "\n",
    "#rename column\n",
    "df_afla.rename(columns={'Content': 'text'}, inplace=True)\n",
    "print(df_afla.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  Chanzo cha picha, Getty Images\\nHabari za hivi...      5\n",
      "1  Chanzo cha picha, Getty Images\\nKiungulia amba...      5\n",
      "2  Kat Watkins, mwanamke anayetumia kiti cha magu...      5\n",
      "3  Chanzo cha picha, GETTTY IMAGES\\nMaumivu ya mo...      5\n",
      "4  Chanzo cha picha, Getty Images\\nOnur Erim\\nBBC...      5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the label mapping\n",
    "label_mapping = ['uchumi', 'kitaifa', 'michezo', 'kimataifa', 'burudani', 'afya']\n",
    "label_to_id = {label: idx for idx, label in enumerate(label_mapping)}\n",
    "\n",
    "# Map text labels to numerical labels in the new dataset\n",
    "df_afla['label'] = df_afla['label'].map(label_to_id)\n",
    "\n",
    "# Display the new DataFrame to ensure labels are mapped correctly\n",
    "print(df_afla.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "df_afla.to_csv('../data/hf_dataset/df_afla-new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files into DataFrames\n",
    "df_michezo = pd.read_csv('../data/hf_dataset/df_michezo-new.csv')\n",
    "df_afla = pd.read_csv('../data/hf_dataset/df_afla-new.csv')\n",
    "df_burudani = pd.read_csv('../data/hf_dataset/df_burudani_new.csv')\n",
    "swahili_dataset = pd.read_csv('../data/hf_dataset/swahili_news_train.csv')\n",
    "\n",
    "# Concatenate the DataFrames with hf dataset \n",
    "merged_df = pd.concat([df_michezo, df_afla,df_burudani,swahili_dataset], ignore_index=True)\n",
    "\n",
    "# save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data/hf_dataset/swahili_labeled_news.csv', index=False)\n",
    "\n",
    "print(\"Datasets merged successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22207\n"
     ]
    }
   ],
   "source": [
    "#check the number of records before merge\n",
    "swahili_dataset = pd.read_csv('../data/hf_dataset/swahili_news_train.csv')\n",
    "print(len(swahili_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24210\n"
     ]
    }
   ],
   "source": [
    "# check the number of records after merged\n",
    "#check the number of records before merge\n",
    "swahili_dataset = pd.read_csv('../data/hf_dataset/swahili_labeled_news.csv')\n",
    "print(len(swahili_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import subprocess\n",
    "\n",
    "# huggingface_bin_path = \"/home/air/.local/bin\"\n",
    "# os.environ[\"PATH\"] = f\"{huggingface_bin_path}:{os.environ['PATH']}\"\n",
    "\n",
    "# subprocess.run([\"huggingface-cli\", \"login\", \"--token\", \"yout token here\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (assuming it's saved as a CSV file)\n",
    "swahili__train_dataset = pd.read_csv('../data/hf_dataset/swahili_labeled_news.csv')\n",
    "swahili_test_dataset = pd.read_csv('../data/hf_dataset/swahili_news_test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 4 0 1 3]\n"
     ]
    }
   ],
   "source": [
    "# Find rows where the 'label' column is 'burudani'\n",
    "labeled_name = swahili__train_dataset['label'].unique()\n",
    "\n",
    "print(labeled_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(swahili__train_dataset)\n",
    "test_dataset = Dataset.from_pandas(swahili_test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DatasetDict with train and test splits\n",
    "dataset_dict = DatasetDict({'train': train_dataset, 'test': test_dataset})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 24210\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7338\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#check dataset dict\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 25/25 [00:00<00:00, 97.05ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:14<00:00, 14.35s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 103.13ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/derekiya/swahili_news/commit/33320ed4f53e9fcbb62699cf59b987644c8d9c83', commit_message='Upload dataset', commit_description='', oid='33320ed4f53e9fcbb62699cf59b987644c8d9c83', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the dataset to Hugging Face Hub\n",
    "dataset_dict.push_to_hub(\"derekiya/swahili_news\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
